{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bd3c4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYSTEMS: ['Land Raider', 'Robot']\n",
      "ACTIVITIES: ['detect obstacle', 'stop drive motor', 'turn land raider', 'resume motion', 'ensure', 'execute obstacle avoidance', 'monitor battery state', 'prevent further movement', 'trigger avoidance maneuver', 'allow', 'update', 'stop movement']\n",
      "ATTRIBUTES: ['distance', 'avoidance threshold', 'turn angle', 'execution period', 'battery state', 'battery voltage']\n",
      "CONSTRAINTS: [{'type': 'upper_bound', 'value': 10.0, 'unit': 'cm'}, {'type': 'exact', 'value': 10.0, 'unit': 'cm'}, {'type': 'upper_bound', 'value': 0.2, 'unit': 's'}, {'type': 'exact', 'value': 0.2, 'unit': 's'}, {'type': 'lower_bound', 'value': 30.0, 'unit': 'deg'}, {'type': 'exact', 'value': 0.5, 'unit': 's'}, {'type': 'strict_upper_bound', 'value': 6.0, 'unit': 'v'}]\n",
      "EXTARACTED INFO AS REQUIREMENT: [('Land Raider', 'detect obstacle', 'distance', {'type': 'upper_bound', 'value': 10.0, 'unit': 'cm'}), ('Land Raider', 'detect obstacle', 'distance', {'type': 'exact', 'value': 10.0, 'unit': 'cm'}), ('Land Raider', 'stop drive motor', 'avoidance threshold', {'type': 'upper_bound', 'value': 0.2, 'unit': 's'}), ('Land Raider', 'stop drive motor', 'avoidance threshold', {'type': 'exact', 'value': 0.2, 'unit': 's'}), ('Land Raider', 'turn land raider', 'turn angle', {'type': 'lower_bound', 'value': 30.0, 'unit': 'deg'}), ('Land Raider', 'detect', 'turn angle', {'type': 'lower_bound', 'value': 30.0, 'unit': 'deg'}), ('Land Raider', 'resume motion', None, None), ('Land Raider', 'ensure', 'execution period', {'type': 'exact', 'value': 0.5, 'unit': 's'}), ('Land Raider', 'execute obstacle avoidance', 'execution period', {'type': 'exact', 'value': 0.5, 'unit': 's'}), ('Land Raider', 'monitor battery state', 'battery voltage', {'type': 'strict_upper_bound', 'value': 6.0, 'unit': 'v'}), ('Land Raider', 'prevent further movement', 'battery voltage', {'type': 'strict_upper_bound', 'value': 6.0, 'unit': 'v'}), ('Robot', 'trigger avoidance maneuver', None, None), ('Robot', 'allow', None, None), ('Robot', 'update', None, None), ('Robot', 'stop movement', None, None)]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "# ----------------------------\n",
    "# NLP setup\n",
    "# ----------------------------\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# ----------------------------\n",
    "# Helpers\n",
    "# ----------------------------\n",
    "\n",
    "def full_subject(token):\n",
    "    \"\"\"Build full subject from compound tokens (text form).\"\"\"\n",
    "    parts = [token.text]\n",
    "    for child in token.children:\n",
    "        if child.dep_ == \"compound\":\n",
    "            parts.insert(0, child.text)\n",
    "    return \" \".join(parts)\n",
    "\n",
    "def normalize_lemmas(tokens):\n",
    "    \"\"\"Convert tokens to a clean lemma phrase (lowercase, no punct/spaces).\"\"\"\n",
    "    out = []\n",
    "    for t in tokens:\n",
    "        if t.is_punct or t.is_space:\n",
    "            continue\n",
    "        lemma = t.lemma_.lower()\n",
    "        if lemma == \"-pron-\":\n",
    "            lemma = t.text.lower()\n",
    "        out.append(lemma)\n",
    "    return \" \".join(out).strip()\n",
    "\n",
    "def lemmatize_phrase(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Lemmatize a phrase and drop determiners like 'a/the'.\n",
    "    Example: 'the avoidance threshold' -> 'avoidance threshold'\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    toks = []\n",
    "    for t in doc:\n",
    "        if t.is_space or t.is_punct:\n",
    "            continue\n",
    "        if t.pos_ == \"DET\":\n",
    "            continue\n",
    "        lemma = t.lemma_.lower()\n",
    "        if lemma == \"-pron-\":\n",
    "            lemma = t.text.lower()\n",
    "        toks.append(lemma)\n",
    "    return re.sub(r\"\\s+\", \" \", \" \".join(toks)).strip()\n",
    "\n",
    "def collect_full_noun_phrase(noun_token):\n",
    "    \"\"\"Collect a fuller noun phrase around NOUN/PROPN using selected dependency children.\"\"\"\n",
    "    keep_deps = {\"compound\", \"amod\", \"poss\", \"nmod\"}\n",
    "    parts = [noun_token]\n",
    "    for ch in noun_token.children:\n",
    "        if ch.dep_ in keep_deps and ch.pos_ in {\"NOUN\", \"PROPN\", \"ADJ\"}:\n",
    "            parts.append(ch)\n",
    "    return sorted(parts, key=lambda x: x.i)\n",
    "\n",
    "def remove_subset_activities(activities):\n",
    "    \"\"\"Remove activities that are strict substrings of longer activities.\"\"\"\n",
    "    cleaned = []\n",
    "    for act in activities:\n",
    "        if any(act != other and act in other for other in activities):\n",
    "            continue\n",
    "        cleaned.append(act)\n",
    "    return cleaned\n",
    "\n",
    "def _add_unique(item, lst, seen):\n",
    "    if item and item not in seen:\n",
    "        seen.add(item)\n",
    "        lst.append(item)\n",
    "\n",
    "# ----------------------------\n",
    "# Activity extraction (lemma + xcomp-aware)\n",
    "# ----------------------------\n",
    "\n",
    "def extract_activity_from_span(span):\n",
    "    \"\"\"\n",
    "    Build activity as lemma-based phrase.\n",
    "\n",
    "    Case A: verbs with xcomp (e.g., allow users to upload X)\n",
    "      -> activity becomes: upload <object>\n",
    "    Case B: normal verb + direct object\n",
    "      -> activity becomes: verb <object>\n",
    "    \"\"\"\n",
    "    verb = None\n",
    "    for t in span:\n",
    "        if t.pos_ == \"VERB\":\n",
    "            verb = t\n",
    "            break\n",
    "    if not verb:\n",
    "        return None\n",
    "\n",
    "    # Case A: xcomp exists (allow ... to upload ...)\n",
    "    for ch in verb.children:\n",
    "        if ch.dep_ == \"xcomp\" and ch.pos_ == \"VERB\":\n",
    "            xverb = ch\n",
    "            for obj in xverb.children:\n",
    "                if obj.dep_ in {\"dobj\", \"obj\"} and obj.pos_ in {\"NOUN\", \"PROPN\"}:\n",
    "                    np_tokens = collect_full_noun_phrase(obj)\n",
    "                    obj_phrase = normalize_lemmas(np_tokens)\n",
    "                    return f\"{xverb.lemma_.lower()} {obj_phrase}\".strip()\n",
    "            return xverb.lemma_.lower()\n",
    "\n",
    "    # Case B: normal direct object\n",
    "    for ch in verb.children:\n",
    "        if ch.dep_ in {\"dobj\", \"obj\"} and ch.pos_ in {\"NOUN\", \"PROPN\"}:\n",
    "            np_tokens = collect_full_noun_phrase(ch)\n",
    "            obj_phrase = normalize_lemmas(np_tokens)\n",
    "            return f\"{verb.lemma_.lower()} {obj_phrase}\".strip()\n",
    "\n",
    "    return verb.lemma_.lower()\n",
    "\n",
    "# ----------------------------\n",
    "# Attributes & Constraints extraction (structured)\n",
    "# ----------------------------\n",
    "\n",
    "_UNIT_CANON = {\n",
    "    \"cm\": \"cm\",\n",
    "    \"centimeter\": \"cm\",\n",
    "    \"centimeters\": \"cm\",\n",
    "    \"s\": \"s\",\n",
    "    \"sec\": \"s\",\n",
    "    \"second\": \"s\",\n",
    "    \"seconds\": \"s\",\n",
    "    \"v\": \"v\",\n",
    "    \"volt\": \"v\",\n",
    "    \"volts\": \"v\",\n",
    "    \"degree\": \"deg\",\n",
    "    \"degrees\": \"deg\",\n",
    "}\n",
    "\n",
    "RE_NUM_UNIT = re.compile(\n",
    "    r\"(?P<num>\\d+(?:\\.\\d+)?)\\s*(?P<unit>cm|centimeters?|seconds?|second|s|deg(?:rees)?|degrees?|v|V|volts?|volt)\\b\"\n",
    ")\n",
    "\n",
    "def _canon_unit(u: str) -> str:\n",
    "    u0 = u.strip().lower()\n",
    "    if u0.startswith(\"deg\"):\n",
    "        return \"deg\"\n",
    "    return _UNIT_CANON.get(u0, u0)\n",
    "\n",
    "def _constraint_type(op: str) -> str:\n",
    "    return {\n",
    "        \"<=\": \"upper_bound\",\n",
    "        \">=\": \"lower_bound\",\n",
    "        \"<\": \"strict_upper_bound\",\n",
    "        \">\": \"strict_lower_bound\",\n",
    "        \"=\": \"exact\",\n",
    "    }.get(op, \"unknown\")\n",
    "\n",
    "def extract_attributes_and_constraints(req: str):\n",
    "    \"\"\"\n",
    "    Returns (per requirement):\n",
    "      attributes_req: list[str]  (lemmatized)\n",
    "      pairs: list[(attribute, constraint_dict)]\n",
    "        where constraint_dict = {\"type\",\"value\",\"unit\"}  (no operator symbols)\n",
    "    \"\"\"\n",
    "    doc = nlp(req)\n",
    "    text_low = req.lower()\n",
    "\n",
    "    attributes_req = []\n",
    "    attr_seen = set()\n",
    "    pairs = []\n",
    "\n",
    "    def add_attr(attr_text: str) -> str:\n",
    "        attr = lemmatize_phrase(attr_text)\n",
    "        _add_unique(attr, attributes_req, attr_seen)\n",
    "        return attr\n",
    "\n",
    "    def add_pair(attr_name: str, op: str, val: str, unit: str):\n",
    "        cons = {\n",
    "            \"type\": _constraint_type(op),\n",
    "            \"value\": float(val),\n",
    "            \"unit\": _canon_unit(unit),\n",
    "        }\n",
    "        pairs.append((attr_name, cons))\n",
    "\n",
    "    # attribute hints from noun chunks\n",
    "    for chunk in doc.noun_chunks:\n",
    "        c = chunk.text.lower()\n",
    "        if any(k in c for k in [\"distance\", \"threshold\", \"voltage\", \"battery state\", \"avoidance threshold\"]):\n",
    "            add_attr(chunk.text)\n",
    "\n",
    "    # at least X deg -> turn angle\n",
    "    if \"at least\" in text_low:\n",
    "        after = text_low.split(\"at least\", 1)[1]\n",
    "        m = RE_NUM_UNIT.search(after)\n",
    "        if m:\n",
    "            unit_c = _canon_unit(m.group(\"unit\"))\n",
    "            if unit_c == \"deg\" and \"turn\" in text_low:\n",
    "                attr = add_attr(\"turn angle\")\n",
    "            else:\n",
    "                attr = add_attr(\"angle\" if unit_c == \"deg\" else \"value\")\n",
    "            add_pair(attr, \">=\", m.group(\"num\"), m.group(\"unit\"))\n",
    "\n",
    "    # below X V -> battery voltage\n",
    "    if \"below\" in text_low:\n",
    "        after = text_low.split(\"below\", 1)[1]\n",
    "        m = RE_NUM_UNIT.search(after)\n",
    "        if m:\n",
    "            if \"voltage\" in text_low or \"battery\" in text_low:\n",
    "                attr = add_attr(\"battery voltage\")\n",
    "            else:\n",
    "                attr = add_attr(\"value\")\n",
    "            add_pair(attr, \"<\", m.group(\"num\"), m.group(\"unit\"))\n",
    "\n",
    "    # within ... X unit -> distance or (avoidance) threshold\n",
    "    if \"within\" in text_low:\n",
    "        within_phrase = text_low.split(\"within\", 1)[1]\n",
    "        m = RE_NUM_UNIT.search(within_phrase)\n",
    "        if m:\n",
    "            if \"distance\" in within_phrase:\n",
    "                attr = add_attr(\"distance\")\n",
    "            elif \"threshold\" in within_phrase and \"avoidance\" in within_phrase:\n",
    "                attr = add_attr(\"avoidance threshold\")\n",
    "            elif \"threshold\" in within_phrase:\n",
    "                attr = add_attr(\"threshold\")\n",
    "            else:\n",
    "                attr = add_attr(\"value\")\n",
    "            add_pair(attr, \"<=\", m.group(\"num\"), m.group(\"unit\"))\n",
    "\n",
    "    # every X s -> execution period\n",
    "    if \"every\" in text_low:\n",
    "        after = text_low.split(\"every\", 1)[1]\n",
    "        m = RE_NUM_UNIT.search(after)\n",
    "        if m:\n",
    "            unit_c = _canon_unit(m.group(\"unit\"))\n",
    "            attr = add_attr(\"execution period\" if unit_c == \"s\" else \"value\")\n",
    "            add_pair(attr, \"=\", m.group(\"num\"), m.group(\"unit\"))\n",
    "\n",
    "    # distance of X cm -> exact distance\n",
    "    if \"distance of\" in text_low:\n",
    "        after = text_low.split(\"distance of\", 1)[1]\n",
    "        m = RE_NUM_UNIT.search(after)\n",
    "        if m:\n",
    "            attr = add_attr(\"distance\")\n",
    "            add_pair(attr, \"=\", m.group(\"num\"), m.group(\"unit\"))\n",
    "\n",
    "    # threshold of X s -> exact (avoidance) threshold\n",
    "    if \"threshold of\" in text_low:\n",
    "        after = text_low.split(\"threshold of\", 1)[1]\n",
    "        m = RE_NUM_UNIT.search(after)\n",
    "        if m:\n",
    "            attr = add_attr(\"avoidance threshold\" if \"avoidance\" in text_low else \"threshold\")\n",
    "            add_pair(attr, \"=\", m.group(\"num\"), m.group(\"unit\"))\n",
    "\n",
    "    return attributes_req, pairs\n",
    "\n",
    "# ----------------------------\n",
    "# Per-requirement extraction (SYSTEMS + ACTIVITIES + ATTR/CONS pairs)\n",
    "# ----------------------------\n",
    "\n",
    "def extract_per_requirement(req: str):\n",
    "    \"\"\"\n",
    "    Returns per requirement:\n",
    "      systems_req: list[str]\n",
    "      activities_req: list[str]\n",
    "      attributes_req: list[str]\n",
    "      attr_cons_pairs: list[(attribute, constraint_dict)]\n",
    "    \"\"\"\n",
    "    doc = nlp(req)\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    systems_req = []\n",
    "    activities_req = []\n",
    "    sys_seen = set()\n",
    "    act_seen = set()\n",
    "\n",
    "    attributes_req, attr_cons_pairs = extract_attributes_and_constraints(req)\n",
    "\n",
    "    for match_id, start, end in matches:\n",
    "        label = nlp.vocab.strings[match_id]\n",
    "        span = doc[start:end]\n",
    "\n",
    "        if label == \"SYSTEM\":\n",
    "            ent_start = start + 1 if doc[start].pos_ == \"DET\" else start\n",
    "            ent_end = end - 1  # exclude 'shall'\n",
    "            entity_span = doc[ent_start:ent_end]\n",
    "            name = entity_span.text.strip()\n",
    "\n",
    "            if any(name != s and name in s for s in systems_req):\n",
    "                continue\n",
    "\n",
    "            if name and name not in sys_seen:\n",
    "                sys_seen.add(name)\n",
    "                systems_req.append(name)\n",
    "\n",
    "        elif label == \"ACTIVITY\":\n",
    "            activity = extract_activity_from_span(span)\n",
    "            if activity and activity not in act_seen:\n",
    "                act_seen.add(activity)\n",
    "                activities_req.append(activity)\n",
    "\n",
    "    activities_req = remove_subset_activities(activities_req)\n",
    "    return systems_req, activities_req, attributes_req, attr_cons_pairs\n",
    "\n",
    "# ----------------------------\n",
    "# Build quadruple relationships: (system, activity, attribute, constraint)\n",
    "# ----------------------------\n",
    "\n",
    "def build_quad_relationships(requirements):\n",
    "    quad = []\n",
    "    for req in requirements:\n",
    "        systems_req, activities_req, attributes_req, attr_cons_pairs = extract_per_requirement(req)\n",
    "\n",
    "        if attr_cons_pairs:\n",
    "            for sys in (systems_req or [None]):\n",
    "                for act in (activities_req or [None]):\n",
    "                    for attr, cons in attr_cons_pairs:\n",
    "                        quad.append((sys, act, attr, cons))\n",
    "        else:\n",
    "            if attributes_req:\n",
    "                for sys in (systems_req or [None]):\n",
    "                    for act in (activities_req or [None]):\n",
    "                        for attr in attributes_req:\n",
    "                            quad.append((sys, act, attr, None))\n",
    "            else:\n",
    "                for sys in (systems_req or [None]):\n",
    "                    for act in (activities_req or [None]):\n",
    "                        quad.append((sys, act, None, None))\n",
    "\n",
    "    return quad\n",
    "\n",
    "# ----------------------------\n",
    "# MAIN\n",
    "# ----------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # SYSTEM matcher pattern\n",
    "    system_pattern2 = [\n",
    "        {\"POS\": \"DET\", \"OP\": \"?\"},\n",
    "        {\"POS\": \"ADJ\", \"OP\": \"?\"},\n",
    "        {\"POS\": {\"IN\": [\"NOUN\", \"PROPN\"]}, \"OP\": \"?\"},\n",
    "        {\"POS\": {\"IN\": [\"NOUN\", \"PROPN\"]}},\n",
    "        {\"LEMMA\": \"shall\", \"POS\": \"AUX\"},\n",
    "    ]\n",
    "\n",
    "    # ACTIVITY matcher pattern\n",
    "    activity_pattern = [\n",
    "        {\"POS\": \"VERB\"},\n",
    "        {\"POS\": \"DET\", \"OP\": \"?\"},\n",
    "        {\"POS\": \"ADV\", \"OP\": \"?\"},\n",
    "        {\"POS\": {\"IN\": [\"NOUN\", \"PROPN\", \"ADJ\"]}, \"OP\": \"?\"},\n",
    "        {\"POS\": {\"IN\": [\"NOUN\", \"PROPN\"]}},\n",
    "    ]\n",
    "\n",
    "    matcher.add(\"SYSTEM\", [system_pattern2])\n",
    "    matcher.add(\"ACTIVITY\", [activity_pattern])\n",
    "\n",
    "    requirements = [\n",
    "        \"The Land Raider shall use the ultrasonic sensor to detect obstacles within a distance of 10 cm\",\n",
    "        \"The Land Raider shall stop the drive motors within the avoidance threshold of 0.2 seconds after obstacle detection\",\n",
    "        \"The Land Raider shall command the drive motors to turn the Land Raider at least 30 degrees away from the detected obstacle\",\n",
    "        \"The Land Raider shall resume forward motion after obstacle clearance is confirmed by the ultrasonic sensor\",\n",
    "        \"The Land Raider shall ensure the microcontroller executes the obstacle avoidance algorithm every 0.5s\",\n",
    "        \"The Land Raider shall monitor battery state and prevent further movement if battery voltage is below 6.0V\",\n",
    "        \"The Robot shall use onboard LEDs to indicate when an obstacle has triggered an avoidance maneuver\",\n",
    "        \"The Robot shall allow users to upload updated obstacle avoidance scripts via USB or Bluetooth\",\n",
    "        \"The Robot shall stop movement if any component critical to obstacle avoidance is malfunctioning\",\n",
    "    ]\n",
    "\n",
    "    # ----------------------------\n",
    "    # Global lists (kept)\n",
    "    # ----------------------------\n",
    "    systems = []\n",
    "    systems_seen = set()\n",
    "\n",
    "    activities = []\n",
    "    activities_seen = set()\n",
    "\n",
    "    attributes = []\n",
    "    attributes_seen = set()\n",
    "\n",
    "    constraints = []  # list[dict] (structured)\n",
    "    quad_relationships = build_quad_relationships(requirements)\n",
    "\n",
    "    # Collect global lists by iterating requirements (consistent with quad)\n",
    "    for r in requirements:\n",
    "        sys_r, act_r, attr_r, pair_r = extract_per_requirement(r)\n",
    "\n",
    "        for s in sys_r:\n",
    "            if s not in systems_seen:\n",
    "                systems_seen.add(s)\n",
    "                systems.append(s)\n",
    "\n",
    "        for a in act_r:\n",
    "            if a not in activities_seen:\n",
    "                activities_seen.add(a)\n",
    "                activities.append(a)\n",
    "\n",
    "        for a in attr_r:\n",
    "            if a not in attributes_seen:\n",
    "                attributes_seen.add(a)\n",
    "                attributes.append(a)\n",
    "\n",
    "        for _, cons in pair_r:\n",
    "            if cons not in constraints:\n",
    "                constraints.append(cons)\n",
    "\n",
    "    activities = remove_subset_activities(activities)\n",
    "\n",
    "    # ----------------------------\n",
    "    # Output\n",
    "    # ----------------------------\n",
    "    print(\"SYSTEMS:\", systems)\n",
    "    print(\"ACTIVITIES:\", activities)\n",
    "    print(\"ATTRIBUTES:\", attributes)\n",
    "    print(\"CONSTRAINTS:\", constraints)\n",
    "    print(\"EXTARACTED INFO AS REQUIREMENT:\", quad_relationships)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
